{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-30 18:50:34.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_datasets\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mIris\u001b[0m\n",
      "\u001b[32m2025-01-30 18:50:34.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_datasets\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mLoan Status\u001b[0m\n",
      "\u001b[32m2025-01-30 18:50:34.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mProcessing Dataset: Loan Status\u001b[0m\n",
      "\u001b[32m2025-01-30 18:50:34.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m295\u001b[0m - \u001b[1mBaseline test roc_auc_score is: 0.7761278195488723\u001b[0m\n",
      "Performing Computation:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Computation: 100%|██████████| 1/1 [20:06<00:00, 1206.59s/it]\n",
      "\u001b[32m2025-01-30 19:10:41.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mapply_kmedoids_clustering\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1m✅ XPER clustering saved in experiment_results_loan5000/loan_status/xper_values/train_xper_clusters.csv\u001b[0m\n",
      "\u001b[32m2025-01-30 19:10:41.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m299\u001b[0m - \u001b[1mXPER done\u001b[0m\n",
      "\u001b[32m2025-01-30 19:10:41.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcluster_feature_based\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1m✅ XPER clustering saved in experiment_results_loan5000/loan_status/xper_values/train_feature_clusters.csv\u001b[0m\n",
      "\u001b[32m2025-01-30 19:10:41.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m306\u001b[0m - \u001b[1mXPER Cluster done\u001b[0m\n",
      "\u001b[32m2025-01-30 19:10:42.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFeature Cluster done\u001b[0m\n",
      "\u001b[32m2025-01-30 19:10:42.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1mPure Clusters: {'xper': {}, 'feature': {}}\u001b[0m\n",
      "Performing Computation:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Computation: 100%|██████████| 1/1 [01:28<00:00, 88.57s/it]\n",
      "\u001b[32m2025-01-30 19:12:11.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_xper\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1m✅ XPER clustering saved in experiment_results_loan5000/loan_status/xper_values/test_xper_clusters.csv\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_xper\u001b[0m:\u001b[36m222\u001b[0m - \u001b[1m2\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_xper\u001b[0m:\u001b[36m222\u001b[0m - \u001b[1m2\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_feature\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1m✅ Feature clustering saved in experiment_results_loan5000/loan_status/xper_values/test_feature_clusters.csv\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_feature\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1m1\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_feature\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mFor cluster 0 the test set predictions were purly class 1, with the following probabilities: [0.73772097 0.97433937 0.9885444  0.979543   0.99085134 0.9835941\n",
      " 0.95868427 0.8428759  0.27938    0.52762   ]\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_feature\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1m2\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_feature\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1m2\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_feature\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1m2\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtest_eval_feature\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1m2\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_datasets\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mBoston Housing\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_datasets\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mWine Quality\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_datasets\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mAbalone\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_datasets\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mBank Marketing\u001b[0m\n",
      "\u001b[32m2025-01-30 19:12:11.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_datasets\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mBike Sharing\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nToDo: \\n\\n1. Potential other clusters\\n2. Compare kernel XPER\\n3. (Compare to benchmark study)\\n4. Run with dataset we got from them during class\\n5. Preprocessing of data and model selection \\n6. (Different Models beyond XGBoost)\\n7. Alter XPER to return also coalititon values to cluster with those values also \\n8. Use feature cluster also for test set\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, r2_score, silhouette_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from XPER.compute.Performance import ModelPerformance\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from loguru import logger\n",
    "from load_data import load_datasets\n",
    "from utils import evaluate_model, initiate_model, identify_problem_type\n",
    "from config import BASE_DIR, SAMPLE_SIZE, N_FEATURES\n",
    "\n",
    "\n",
    "# Create a directory to store results\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, target_col: str, dataset_name: str, sample_size: int = 500, n_features: int = 6):\n",
    "    \"\"\"Preprocess dataset by encoding categorical features, splitting into train-test sets, and determining problem type.\"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Limit dataset size\n",
    "    if df.shape[0] > sample_size:\n",
    "        df = df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Save the full dataset\n",
    "    dataset_dir = os.path.join(BASE_DIR, dataset_name.replace(\" \", \"_\"))\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    df.to_csv(os.path.join(data_dir, \"full_dataset.csv\"), index=False)\n",
    "    \n",
    "    # Select features and target\n",
    "    X = df.drop(columns=[target_col]).iloc[:, :n_features]\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "    # Encode categorical features\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    if categorical_cols:\n",
    "        encoder = OrdinalEncoder()\n",
    "        X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols])\n",
    "        X_test[categorical_cols] = encoder.transform(X_test[categorical_cols])\n",
    "    \n",
    "    # Determine problem type\n",
    "    model_type, classification, num_classes = identify_problem_type(dataset_name, y_train, y_test, target_col, label_encoder)\n",
    "    \n",
    "    # Reset indexes\n",
    "    for df in [X_train, X_test, y_train, y_test]:\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, model_type, num_classes, classification\n",
    "\n",
    "def compute_xper(X: pd.DataFrame, y: pd.DataFrame, model, classification: bool):\n",
    "    \"\"\"Compute XPER values for model explainability and apply clustering for instance-level insights.\"\"\"\n",
    "    XPER_ = ModelPerformance(X.values, y.values, X.values, y.values, model, sample_size = X.shape[0])\n",
    "    metric = \"AUC\" if classification else \"R2\"\n",
    "    phi, phi_i_j = XPER_.calculate_XPER_values([metric])\n",
    "    \n",
    "    save_xper_results(X, phi, phi_i_j)\n",
    "    \n",
    "    return apply_kmedoids_clustering(X, phi_i_j)\n",
    "\n",
    "\n",
    "def save_xper_results(X: pd.DataFrame, phi, phi_i_j):\n",
    "    \"\"\"Save XPER values to CSV files.\"\"\"\n",
    "    pd.DataFrame(phi, columns=[\"Global XPER\"]).to_csv(os.path.join(xper_dir, \"train_global_xper.csv\"), index=False)\n",
    "    \n",
    "    phi_i_j_df = pd.DataFrame(phi_i_j, columns=[\"Benchmark\"] + list(X.columns))\n",
    "    phi_i_j_df.to_csv(os.path.join(xper_dir, \"train_per_instance_xper.csv\"), index=False)\n",
    "\n",
    "\n",
    "def apply_kmedoids_clustering(X: pd.DataFrame, phi_i_j):\n",
    "    \"\"\"Apply K-Medoids clustering on XPER values and save the best clustering model.\"\"\"\n",
    "    XPER_values = phi_i_j[:, 1:]  # Remove benchmark column\n",
    "    scaler = StandardScaler()\n",
    "    XPER_scaled = scaler.fit_transform(XPER_values)\n",
    "    \n",
    "    best_score, best_n_clusters, best_kmedoid = -1, 2, None\n",
    "    for n_clusters in range(2, 6):\n",
    "        kmedoid = KMedoids(n_clusters=n_clusters, random_state=3).fit(XPER_scaled)\n",
    "        labels = kmedoid.labels_\n",
    "        score = silhouette_score(XPER_scaled, labels)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score, best_n_clusters, best_kmedoid = score, n_clusters, kmedoid\n",
    "    \n",
    "    joblib.dump(best_kmedoid, os.path.join(model_dir, \"best_xper_kmedoid.pkl\"))\n",
    "    \n",
    "    xper_cluster_df = pd.DataFrame({\"Index\": X.index, \"Cluster\": best_kmedoid.labels_})\n",
    "    xper_cluster_df.to_csv(os.path.join(xper_dir, \"train_xper_clusters.csv\"), index=False)\n",
    "    \n",
    "    logger.info(f\"✅ XPER clustering saved in {xper_dir}/train_xper_clusters.csv\")\n",
    "    \n",
    "    return best_kmedoid.labels_, best_n_clusters, best_score, scaler\n",
    "\n",
    "def cluster_feature_based(X: pd.DataFrame):\n",
    "    \"\"\"Apply K-Medoids clustering on scaled feature data.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    best_score, best_n_clusters, best_kmedoid = -1, 2, None\n",
    "    for n_clusters in range(2, 6):\n",
    "        kmedoid = KMedoids(n_clusters=n_clusters, random_state=3).fit(X_scaled)\n",
    "        labels = kmedoid.labels_\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score, best_n_clusters, best_kmedoid = score, n_clusters, kmedoid\n",
    "    \n",
    "    joblib.dump(best_kmedoid, os.path.join(model_dir, \"best_feature_kmedoid.pkl\"))\n",
    "\n",
    "    feature_cluster_df = pd.DataFrame({\"Index\": X.index, \"Cluster\": best_kmedoid.labels_})\n",
    "    feature_cluster_df.to_csv(os.path.join(xper_dir, \"train_feature_clusters.csv\"), index=False)\n",
    "    \n",
    "    logger.info(f\"✅ XPER clustering saved in {xper_dir}/train_feature_clusters.csv\")\n",
    "    \n",
    "    return best_kmedoid.labels_, best_n_clusters, best_score, scaler\n",
    "\n",
    "def train_and_evaluate_models(X_train: pd.DataFrame, y_train: pd.DataFrame, target_col: str, cluster_labels: np.ndarray, model_type: str, model_prefix: str = None):\n",
    "    \"\"\"Train and evaluate models for each feature-based cluster.\"\"\"\n",
    "    X_train[\"Cluster\"] = cluster_labels\n",
    "    cluster_results, label_encoders = {}, {}\n",
    "    \n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        cluster_indices = X_train[X_train[\"Cluster\"] == cluster].index\n",
    "        X_train_cluster = X_train.loc[cluster_indices].drop(columns=[\"Cluster\"])\n",
    "        y_train_cluster = y_train.loc[cluster_indices]\n",
    "        \n",
    "        if isinstance(y_train_cluster, pd.Series):\n",
    "            y_train_cluster = y_train_cluster.to_frame()\n",
    "            y_train_cluster = y_train_cluster.rename(columns = {0: target_col})\n",
    "        \n",
    "        unique_classes = np.sort(y_train_cluster[target_col].unique())\n",
    "        \n",
    "        if model_type in [\"binary\", \"multiclass\"] and len(unique_classes) == 1:\n",
    "            logger.info(f\"{model_prefix} cluster {cluster} is purely class {unique_classes[0]}. Assigning perfect score.\")\n",
    "            cluster_results[cluster] = {\"Score\": 1.0, \"Accuracy\": 1.0, \"Cluster Size\": len(cluster_indices), \"Train Time (s)\": \"Pure Cluster\"}\n",
    "            pure_clusters[model_prefix][str(cluster)] = unique_classes[0]\n",
    "            continue\n",
    "        \n",
    "        temp_encoder = LabelEncoder() if model_type in [\"binary\", \"multiclass\"] else None\n",
    "        if temp_encoder:\n",
    "            temp_encoder.fit(unique_classes)\n",
    "            y_train_cluster_encoded = temp_encoder.transform(y_train_cluster[target_col])\n",
    "            label_encoders[cluster] = temp_encoder\n",
    "        else:\n",
    "            y_train_cluster_encoded = y_train_cluster[target_col].values\n",
    "        \n",
    "        start_time = time.time()\n",
    "        cluster_model = initiate_model(model_type, len(unique_classes) if model_type != \"regression\" else None)\n",
    "        cluster_model.fit(X_train_cluster, y_train_cluster_encoded)\n",
    "        train_time = round(time.time() - start_time, 2)\n",
    "        \n",
    "        joblib.dump(cluster_model, os.path.join(model_dir, f\"{model_prefix}_cluster_{cluster}.pkl\"))\n",
    "        pd.concat([X_train_cluster, y_train_cluster], axis=1).to_csv(os.path.join(data_dir, f\"{model_prefix}_cluster_{cluster}.csv\"), index=False)\n",
    "        \n",
    "        y_pred_temp = cluster_model.predict(X_train_cluster)\n",
    "        y_pred = temp_encoder.inverse_transform(y_pred_temp) if temp_encoder else y_pred_temp\n",
    "        \n",
    "        # **Compute Scores**\n",
    "        if model_type == \"multiclass\":\n",
    "            if np.unique(y_train_cluster_encoded).shape[0] > 2:\n",
    "                auc_score = roc_auc_score(y_train_cluster_encoded, cluster_model.predict_proba(X_train_cluster), multi_class=\"ovr\")\n",
    "                accuracy = np.mean(y_train_cluster_encoded == y_pred)\n",
    "            else:\n",
    "                auc_score = roc_auc_score(y_train_cluster_encoded, cluster_model.predict_proba(X_train_cluster)[:, 1])\n",
    "                accuracy = np.mean(y_train_cluster_encoded == y_pred)\n",
    "\n",
    "        elif model_type == \"binary\":\n",
    "            auc_score = roc_auc_score(y_train_cluster_encoded, cluster_model.predict_proba(X_train_cluster)[:, 1])\n",
    "            accuracy = np.mean(y_train_cluster_encoded == y_pred)\n",
    "        else:\n",
    "            auc_score, accuracy = None, None\n",
    "            mse, r2 = mean_squared_error(y_train_cluster_encoded, y_pred), r2_score(y_train_cluster_encoded, y_pred)\n",
    "        \n",
    "        cluster_results[cluster] = {\"AUC/R² Score\": auc_score if model_type in [\"binary\", \"multiclass\"] else r2, \"Accuracy\": accuracy, \"Cluster Size\": len(cluster_indices), \"Train Time (s)\": train_time}\n",
    "    \n",
    "    return cluster_results, label_encoders, pure_clusters\n",
    "\n",
    "def test_eval_xper(X_test: pd.DataFrame, y_test: pd.DataFrame, pure_clusters: dict, classification: bool, scaler: StandardScaler, label_encoder: LabelEncoder):\n",
    "    \"\"\"Evaluate test data using trained models and XPER clustering.\"\"\"\n",
    "\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    models = {fname.split('.')[0]: joblib.load(os.path.join(model_dir, fname)) for fname in os.listdir(model_dir) if fname.endswith(\".pkl\")}\n",
    "    \n",
    "    XPER_ = ModelPerformance(X_test.values, y_test.values, X_test.values, y_test.values, models['baseline_model'])\n",
    "    phi, phi_i_j = XPER_.calculate_XPER_values([\"AUC\"] if classification else [\"R2\"])\n",
    "    \n",
    "    pd.DataFrame(phi, columns=[\"Global XPER\"]).to_csv(os.path.join(xper_dir, \"test_global_xper.csv\"), index=False)\n",
    "    pd.DataFrame(phi_i_j, columns=[\"Benchmark\"] + list(X_test.columns)).to_csv(os.path.join(xper_dir, \"test_per_instance_xper.csv\"), index=False)\n",
    "    \n",
    "    XPER_scaled = scaler.transform(phi_i_j[:, 1:])\n",
    "    predicted_labels = models['best_xper_kmedoid'].predict(XPER_scaled)\n",
    "    X_test[\"Cluster\"] = predicted_labels\n",
    "    pd.DataFrame({\"Index\": X_test.index, \"Cluster\": predicted_labels}).to_csv(os.path.join(xper_dir, \"test_xper_clusters.csv\"), index=False)\n",
    "    \n",
    "    logger.info(f\"✅ XPER clustering saved in {xper_dir}/test_xper_clusters.csv\")\n",
    "    \n",
    "    cluster_results = {}\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        cluster_indices = X_test[X_test[\"Cluster\"] == cluster].index\n",
    "        X_test_cluster = X_test.loc[cluster_indices].drop(columns=[\"Cluster\"])\n",
    "        y_test_cluster = y_test.loc[cluster_indices]\n",
    "        \n",
    "        try:\n",
    "            cluster_model = models[f'xper_cluster_{cluster}']\n",
    "            y_pred_temp = cluster_model.predict(X_test_cluster)\n",
    "            y_pred = label_encoder[cluster].inverse_transform(y_pred_temp)\n",
    "            y_pred_proba = cluster_model.predict_proba(X_test_cluster)[:, 1]\n",
    "        except KeyError:\n",
    "            logger.debug(\"KeyError XPER\")\n",
    "            logger.info(f\"Pure cluster: {pure_clusters['xper'][str(cluster)]}\")\n",
    "            y_pred = np.full(X_test_cluster.shape[0], pure_clusters['xper'][str(cluster)])\n",
    "            auc_prob_perfect = 0.999 if pure_clusters['xper'][str(cluster)] == \"1\" else 0.001\n",
    "            y_pred_proba = np.full(X_test_cluster.shape[0], auc_prob_perfect)\n",
    "\n",
    "        logger.info(len(np.unique(y_test_cluster.values))) #NOTE: If y_test_cluster only has one class auc fails.\n",
    "        if len(np.unique(y_test_cluster.values)) != 2:\n",
    "            logger.info(f\"For cluster {cluster} the test set predictions were purly class {y_test_cluster.values[0]}, with the following probabilities: {y_pred_proba}\")\n",
    "            auc_score = 0.5\n",
    "        else:\n",
    "            auc_score = roc_auc_score(y_test_cluster.values, y_pred_proba)\n",
    "        accuracy = np.mean(y_test_cluster.values == y_pred)\n",
    "        \n",
    "        cluster_results[cluster] = {\"AUC Score\": auc_score, \"Accuracy\": accuracy, \"Cluster Size\": len(cluster_indices)}\n",
    "    \n",
    "    return cluster_results\n",
    "\n",
    "def test_eval_feature(X_test: pd.DataFrame, y_test: pd.DataFrame, pure_clusters: dict, classification: bool, scaler: StandardScaler, label_encoder: LabelEncoder):\n",
    "    \"\"\"Evaluate test data using trained models and feature clustering.\"\"\"\n",
    "    \n",
    "    X_test = X_test.copy()\n",
    "    \n",
    "    models = {fname.split('.')[0]: joblib.load(os.path.join(model_dir, fname)) for fname in os.listdir(model_dir) if fname.endswith(\".pkl\")}\n",
    "    \n",
    "    X_scaled = scaler.transform(X_test)\n",
    "    predicted_labels = models['best_feature_kmedoid'].predict(X_scaled)\n",
    "    X_test[\"Cluster\"] = predicted_labels\n",
    "    pd.DataFrame({\"Index\": X_test.index, \"Cluster\": predicted_labels}).to_csv(os.path.join(xper_dir, \"test_feature_clusters.csv\"), index=False)\n",
    "    \n",
    "    logger.info(f\"✅ Feature clustering saved in {xper_dir}/test_feature_clusters.csv\")\n",
    "    \n",
    "    cluster_results = {}\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        cluster_indices = X_test[X_test[\"Cluster\"] == cluster].index\n",
    "        X_test_cluster = X_test.loc[cluster_indices].drop(columns=[\"Cluster\"])\n",
    "        y_test_cluster = y_test.loc[cluster_indices]\n",
    "        \n",
    "        try:\n",
    "            cluster_model = models[f'feature_cluster_{cluster}']\n",
    "            y_pred_temp = cluster_model.predict(X_test_cluster)\n",
    "            y_pred = label_encoder[cluster].inverse_transform(y_pred_temp)\n",
    "            y_pred_proba = cluster_model.predict_proba(X_test_cluster)[:, 1] #NOTE: indexing only works for binary classification\n",
    "        except KeyError:\n",
    "            logger.debug(\"KeyError Feature\")\n",
    "            logger.info(f\"Pure cluster: {pure_clusters['feature'][str(cluster)]}\")\n",
    "            y_pred = np.full(X_test_cluster.shape[0], pure_clusters['feature'][str(cluster)])\n",
    "            auc_prob_perfect = 0.999 if pure_clusters['feature'][str(cluster)] == \"1\" else 0.001\n",
    "            y_pred_proba = np.full(X_test_cluster.shape[0], auc_prob_perfect)\n",
    "\n",
    "        logger.info(len(np.unique(y_test_cluster.values))) #NOTE: If y_test_cluster only has one class auc fails.\n",
    "        if len(np.unique(y_test_cluster.values)) != 2:\n",
    "            logger.info(f\"For cluster {cluster} the test set predictions were purly class {y_test_cluster.values[0]}, with the following probabilities: {y_pred_proba}\")\n",
    "            auc_score = 0.5\n",
    "        else:\n",
    "            auc_score = roc_auc_score(y_test_cluster.values, y_pred_proba)\n",
    "        accuracy = np.mean(y_test_cluster.values == y_pred)\n",
    "        \n",
    "        cluster_results[cluster] = {\"AUC Score\": auc_score, \"Accuracy\": accuracy, \"Cluster Size\": len(cluster_indices)}\n",
    "    \n",
    "    return cluster_results\n",
    "\n",
    "\n",
    "def main(dataset_name: str, data: tuple):\n",
    "    \"\"\"Process dataset, train models, compute XPER-based and feature-based clustering, and store results.\"\"\"\n",
    "    df, target_col = data\n",
    "    logger.info(f\"Processing Dataset: {dataset_name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Preprocess Data\n",
    "    X_train, X_test, y_train, y_test, model_type, num_classes, classification = preprocess_data(df, target_col, dataset_name, sample_size=SAMPLE_SIZE, n_features=N_FEATURES)\n",
    "    \n",
    "    # Train Baseline Model\n",
    "    baseline_model = initiate_model(model_type, num_classes)\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "    joblib.dump(baseline_model, os.path.join(model_dir, \"baseline_model.pkl\"))\n",
    "    \n",
    "    # Evaluate Baseline Model\n",
    "    baseline_score_train, baseline_score_test = evaluate_model(baseline_model, X_train, X_test, y_train, y_test, model_type)\n",
    "    logger.info(f\"Baseline test roc_auc_score is: {baseline_score_test}\")\n",
    "    \n",
    "    # Compute XPER-Based Clustering\n",
    "    xper_cluster_labels, xper_best_n_clusters, xper_best_score, xper_scaler = compute_xper(X_train, y_train, baseline_model, classification)\n",
    "    logger.info(\"XPER done\")\n",
    "    \n",
    "    # Run Feature-Based KMedoids Clustering\n",
    "    feature_cluster_labels, feature_best_n_clusters, feature_best_score, feature_scaler = cluster_feature_based(X_train)\n",
    "    \n",
    "    # Train Models for Each Cluster\n",
    "    xper_cluster_results, label_encoder_xper, pure_clusters_xper = train_and_evaluate_models(X_train, y_train, target_col, xper_cluster_labels, model_type, \"xper\")\n",
    "    logger.info(\"XPER Cluster done\")\n",
    "    feature_cluster_results, label_encoder_feature, pure_clusters_feature = train_and_evaluate_models(X_train, y_train, target_col, feature_cluster_labels, model_type, \"feature\")\n",
    "    logger.info(\"Feature Cluster done\")\n",
    "\n",
    "    logger.info(f\"Pure Clusters: {pure_clusters}\")\n",
    "    \n",
    "    # Test Model on Clusters\n",
    "    test_xper_cluster_results = test_eval_xper(X_test, y_test, pure_clusters_xper, classification, xper_scaler, label_encoder_xper)\n",
    "    test_feature_cluster_results = test_eval_feature(X_test, y_test, pure_clusters_feature, classification, feature_scaler, label_encoder_feature)\n",
    "\n",
    "    # Store Results\n",
    "    result = {\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Model Type\": model_type,\n",
    "        \"Sample Count\": X_train.shape[0],\n",
    "        \"Feature Count\": X_train.shape[1],\n",
    "        \"Baseline Model AUC/R² Train\": baseline_score_train,\n",
    "        \"Baseline Model AUC/R² Test\": baseline_score_test,\n",
    "        \"XPER-Based Cluster Count\": xper_best_n_clusters,\n",
    "        \"XPER-Based Silhouette Score\": xper_best_score,\n",
    "        \"XPER-Based Per-Cluster Scores\": xper_cluster_results,\n",
    "        \"Feature-Based Cluster Count\": feature_best_n_clusters,\n",
    "        \"Feature-Based Silhouette Score\": feature_best_score,\n",
    "        \"Feature-Based Per-Cluster Scores\": feature_cluster_results,\n",
    "        \"Test XPER Cluster Results\": test_xper_cluster_results,\n",
    "        \"Test Feature Cluster Results\": test_feature_cluster_results,\n",
    "        \"Computation Time (s)\": round(time.time() - start_time, 2),\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_directories(folder_name: str):\n",
    "    \"\"\"Create necessary directories for dataset processing.\"\"\"\n",
    "    global model_dir, data_dir, xper_dir, pure_clusters\n",
    "    pure_clusters = {\"xper\": {}, \"feature\": {}}\n",
    "    model_dir = os.path.join(BASE_DIR, folder_name, \"models\")\n",
    "    data_dir = os.path.join(BASE_DIR, folder_name, \"data\")\n",
    "    xper_dir = os.path.join(BASE_DIR, folder_name, \"xper_values\")\n",
    "    for directory in [model_dir, data_dir, xper_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "def process_datasets():\n",
    "    \"\"\"Load datasets, run main processing, and save results.\"\"\"\n",
    "    datasets = load_datasets()\n",
    "    results = []\n",
    "    \n",
    "    for dataset_name, (df, target_col) in datasets.items():\n",
    "        folder_name = dataset_name.lower().replace(\" \", \"_\")\n",
    "        \n",
    "        # Create Directories\n",
    "        create_directories(folder_name)\n",
    "        logger.info(dataset_name)\n",
    "        \n",
    "        if dataset_name == \"Loan Status\": #NOTE: Change here to allow other data sets\n",
    "            result = main(dataset_name, (df, target_col))\n",
    "            pd.DataFrame(result).to_csv(os.path.join(BASE_DIR, folder_name, \"final_results.csv\"))\n",
    "            results.append(result)\n",
    "    \n",
    "    # Save Overall Results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(BASE_DIR, \"overall_results.csv\"))\n",
    "\n",
    "    return results_df\n",
    "    \n",
    "# Execute dataset processing\n",
    "results_df = process_datasets()\n",
    "\n",
    "\"\"\"\n",
    "ToDo: \n",
    "\n",
    "1. Potential other clusters\n",
    "2. Compare kernel XPER\n",
    "3. (Compare to benchmark study)\n",
    "4. Run with dataset we got from them during class\n",
    "5. Preprocessing of data and model selection \n",
    "6. (Different Models beyond XGBoost)\n",
    "7. Alter XPER to return also coalititon values to cluster with those values also \n",
    "8. Use feature cluster also for test set\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dataset', 'Model Type', 'Sample Count', 'Feature Count',\n",
       "       'Baseline Model AUC/R² Train', 'Baseline Model AUC/R² Test',\n",
       "       'XPER-Based Cluster Count', 'XPER-Based Silhouette Score',\n",
       "       'XPER-Based Per-Cluster Scores', 'Feature-Based Cluster Count',\n",
       "       'Feature-Based Silhouette Score', 'Feature-Based Per-Cluster Scores',\n",
       "       'Test XPER Cluster Results', 'Test Feature Cluster Results',\n",
       "       'Computation Time (s)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'AUC Score': 0.9399038461538461, 'Accuracy': 0.9, 'Cluster Size': 60},\n",
       " 1: {'AUC Score': 0.9604651162790698,\n",
       "  'Accuracy': 0.9206349206349206,\n",
       "  'Cluster Size': 63}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\"Test XPER Cluster Results\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'AUC/R² Score': 1.0,\n",
       "  'Accuracy': 0.9848484848484849,\n",
       "  'Cluster Size': 66,\n",
       "  'Train Time (s)': 0.12},\n",
       " 1: {'AUC/R² Score': 1.0,\n",
       "  'Accuracy': 1.0,\n",
       "  'Cluster Size': 165,\n",
       "  'Train Time (s)': 0.16},\n",
       " 2: {'AUC/R² Score': 1.0,\n",
       "  'Accuracy': 1.0,\n",
       "  'Cluster Size': 79,\n",
       "  'Train Time (s)': 0.14},\n",
       " 3: {'AUC/R² Score': 1.0,\n",
       "  'Accuracy': 1.0,\n",
       "  'Cluster Size': 32,\n",
       "  'Train Time (s)': 0.09},\n",
       " 4: {'AUC/R² Score': 1.0,\n",
       "  'Accuracy': 1.0,\n",
       "  'Cluster Size': 149,\n",
       "  'Train Time (s)': 0.19}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Feature-Based Per-Cluster Scores'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'AUC Score': 0.5, 'Accuracy': 0.9, 'Cluster Size': 10},\n",
       " 1: {'AUC Score': 0.6764705882352942,\n",
       "  'Accuracy': 0.717948717948718,\n",
       "  'Cluster Size': 39},\n",
       " 2: {'AUC Score': 0.8611111111111112,\n",
       "  'Accuracy': 0.9545454545454546,\n",
       "  'Cluster Size': 22},\n",
       " 3: {'AUC Score': 0.0, 'Accuracy': 0.2857142857142857, 'Cluster Size': 7},\n",
       " 4: {'AUC Score': 0.7844827586206897,\n",
       "  'Accuracy': 0.7111111111111111,\n",
       "  'Cluster Size': 45}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\"Test Feature Cluster Results\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
